<!-- PROJECT LOGO -->
<br />
<p align="center">
  <h3 align="center">COMET-ATOMIC-En-Zh</h3>

  <p align="center">
   		COMET-ATOMIC ja's translate demonstration in English and Chinese,
      A commonsense knowledge graph on events translate from Waseda University.
    <br />
  </p>
</p>

### Brief introduction
Day-to-Day commonsense reasoning can be operationalized through a densely connected collection of inferential knowledge. Look up below picture:

<img src="pics/ATOMIC.png" width = "200"/>

#### Below is the discussion in [ATOMIC paper](https://arxiv.org/pdf/1811.00146.pdf)<br/>
<b>
â€œX repels Yâ€™s attackâ€, we can immediately infer various plausible facts surrounding that event. In terms of the plausible motivations behind the event, X probably wants to protect herself. As for Xr
the plausible pre-conditions prior to the event, X may have a
been trained in self-defense to successfully fend off Yâ€™s attack. We can also infer the plausible characteristics of X; she might be strong, skilled, and brave. As a result of the
event, X probably feels angry and might want to file a police report. Y, on the other hand, might feel scared of getting caught and want to run away.
</b>

<br>
<br>
If you want to see an example in truly data construction, you can look below translate data sample demonstrationã€‚

<br/>
<br/>

Waseda University labeled a dataset on [nlp-waseda/comet-atomic-ja](https://github.com/nlp-waseda/comet-atomic-ja) in Japanese and investigate whether models can learn to perform If-Then commonsense inference given a previously unseen event. they explore GPT2 and T5 model respectively. (given an event phrase e and an inference dimension c, the models generates the target t = fÎ¸ (e, c).)<br/>
With the help of nowadays Prompt learning problem modeling approach. This can be done easily.

This project focus on translate their corpus into English and Chinese, train T5 style models to check the ability of Prompt learning's adaptability to deal with this kind of problem in English and Chinese.

### Translate data sample demonstration
#### In Japanese (Original)
An example of the JSON objects is as follows:
```json
{'event': {'event': 'XãŒãƒ‘ãƒãƒ³ã‚³å±‹ã¸è¡Œã', 'mental_state': 'XãŒãƒ‘ãƒãƒ³ã‚³å±‹ã¸è¡Œã'},
 'inference': {'event': {'before': ['XãŒå°é£ã„ã‚’ã‚‚ã‚‰ã†',
    'XãŒãƒ‘ãƒãƒ³ã‚³ã§å‹ã¤',
    'XãŒé‡‘ã‚’ç”¨æ„ã™ã‚‹',
    'XãŒã‚®ãƒ£ãƒ³ãƒ–ãƒ«ä¾å­˜ç—‡ã ã¨è‡ªè¦šã™ã‚‹',
    'XãŒè»Šã‚’é‹è»¢ã™ã‚‹',
    'XãŒé‡‘ã‚’ç¨¼ã',
    'XãŒé‡‘ã‚’æŒã£ã¦ã„ã‚‹',
    'XãŒæ™‚é–“çš„ä½™è£•ã‚’æŒã¤'],
   'after': ['XãŒè² ã‘ã‚‹']},
  'mental_state': {'before': ['æ™‚é–“ã‚’ã¤ã¶ã—ãŸã„',
    'ã‚®ãƒ£ãƒ³ãƒ–ãƒ«ãŒã—ãŸã„',
    'ä½•ã‹é¢ç™½ã„ã“ã¨ãªã„ã‹ãª',
    'æ™‚é–“ã¤ã¶ã—ã ',
    'æš‡ã ',
    'ãŠé‡‘ãŒæ¬²ã—ã„',
    'ãŠé‡‘ã‚’å„²ã‘ã‚‹',
    'ã‚¹ãƒˆãƒ¬ã‚¹ç™ºæ•£ã—ãŸã„'],
   'after': ['ãŠé‡‘ã‚’å¤±ã†',
    'ãŠé‡‘ãŒãªããªã£ãŸ',
    'ãŠé‡‘ã‚’ãŸãã•ã‚“ä½¿ã†',
    'ã‚‚ã†å°‘ã—ã—ãŸã‚‰å¸°ã‚‹',
    'ãŠé‡‘ãŒæ¸›ã‚‹',
    'ã¾ãŸè² ã‘ãŸ',
    'å½“ãŸã‚Šãã†ã ',
    'å‹ã£ãŸã‚‰å¬‰ã—ã„',
    'è² ã‘ã¦å¸°ã£ã¦ãã‚‹',
    'ãŠé‡‘ãŒãªããªã‚‹']}}}
```

#### In English (Translated)
An example of the JSON objects is as follows:
```json
{'en_event': {'event': 'X is going to the pachinko parlor',
  'mental_state': 'X is going to the pachinko parlor'},
 'en_inference': {'event': {'before': ['X gets an allowance',
    'X wins at pachinko.',
    'X gets the money.',
    'Realize X has a gambling problem',
    'X drives a car',
    'X makes money',
    'X has money',
    'X has time to spare'],
   'after': ['X will lose']},
  'mental_state': {'before': ['X wants to kill time',
    'X wants to gamble',
    'I need something fun to do',
    'X is killing time',
    "I'm not busy",
    'I want money',
    'Make some money',
    'I want to relieve stress'],
   'after': ['Lose money',
    'Money is running out',
    'Spend a lot of money',
    "I'll be home in a little while",
    'X will have less money',
    'I lost again.',
    "I think I'm going to win.",
    "I'll be happy if I win",
    'X comes home defeated',
    'X runs out of money']}}}
```

#### In Chinese (Translated)
An example of the JSON objects is as follows:
```json
{'zh_event': {'event': 'Xè¦å»æŸé’å“¥åº—ã€‚', 'mental_state': 'Xè¦å»æŸé’å“¥åº—ã€‚'},
 'zh_inference': {'event': {'before': ['Xå¾—åˆ°ä¸€ç¬”æ´¥è´´',
    'Xåœ¨å¼¹å­æœºä¸Šèµ¢äº†ã€‚',
    'Xæ‹¿åˆ°é’±',
    'Xæ„è¯†åˆ°è‡ªå·±æœ‰èµŒåšé—®é¢˜',
    'Xé©¾é©¶æ±½è½¦',
    'X æŒ£é’±',
    'Xæœ‰é’±äº†',
    'Xæœ‰æ—¶é—´'],
   'after': ['Xè¾“äº†ä¸€åœºæ¯”èµ›']},
  'mental_state': {'before': ['Xæƒ³æ‰“å‘æ—¶é—´',
    'Xæƒ³èµŒåš',
    'æˆ‘éœ€è¦ä¸€äº›æœ‰è¶£çš„äº‹æƒ…æ¥åš',
    'Xåœ¨æ‰“å‘æ—¶é—´',
    'æˆ‘ä¸å¿™ã€‚',
    'æˆ‘æƒ³è¦é’±',
    'èµšç‚¹é’±',
    'æˆ‘æƒ³ç¼“è§£å‹åŠ›'],
   'after': ['å¤±å»äº†é‡‘é’±ã€‚',
    'æˆ‘å·²ç»æ²¡æœ‰é’±äº†',
    'æˆ‘èŠ±äº†å¾ˆå¤šé’±',
    'æˆ‘ä¸€ä¼šå„¿å°±å›å®¶äº†',
    'Xæœ‰æ›´å°‘çš„é’±',
    'æˆ‘åˆè¾“äº†ã€‚',
    'æˆ‘æƒ³æˆ‘è¦èµ¢äº†ã€‚',
    'å¦‚æœæˆ‘èµ¢äº†ï¼Œæˆ‘ä¼šå¾ˆé«˜å…´ã€‚',
    'Xè´¥å…´è€Œå½’',
    'Xé’±ç”¨å®Œäº†']}}}
```

### Models

I finetuned the English and Chinese T5-base and Lora-based (with the help of [peft](https://github.com/huggingface/peft)) T5-large model on the built graph.<br/>
More info and examples about Lora can be seen in [https://github.com/svjack/ControlLoRA-Chinese](https://github.com/svjack/ControlLoRA-Chinese), it is a Lora
application in Stable Diffusion domain to control the output of image with the help
of Lora-based ControlNet.

#### Installtation
```bash
pip install -r requirements.txt
```

The models are available at Huggingface Models:

|Name |HuggingFace Model link| HuggingFace Space link |
|---------|--------|-------|
|English Comet Atomic  ğŸ¢| https://huggingface.co/svjack/comet-atomic-en | https://huggingface.co/spaces/svjack/English-Comet-Atomic |
|Chinese Comet Atomic ğŸš€| https://huggingface.co/svjack/comet-atomic-zh | https://huggingface.co/spaces/svjack/Chinese-Comet-Atomic |
|Chinese Comet Atomic T5 Lora ğŸš€| https://huggingface.co/svjack/mt0-large-comet-atomic-zh-peft-early-cpu ||

You can try them online. Or check the model card to use them by yourself.

<!-- CONTACT -->
## Contact

<!--
Your Name - [@your_twitter](https://twitter.com/your_username) - email@example.com
-->
svjack - svjackbt@gmail.com - ehangzhou@outlook.com

<!--
Project Link: [https://github.com/your_username/repo_name](https://github.com/your_username/repo_name)
-->
Project Link:[https://github.com/svjack/COMET-ATOMIC-En-Zh](https://github.com/svjack/COMET-ATOMIC-En-Zh)


<!-- ACKNOWLEDGEMENTS -->
## Acknowledgements
<!--
* [GitHub Emoji Cheat Sheet](https://www.webpagefx.com/tools/emoji-cheat-sheet)
* [Img Shields](https://shields.io)
* [Choose an Open Source License](https://choosealicense.com)
* [GitHub Pages](https://pages.github.com)
* [Animate.css](https://daneden.github.io/animate.css)
* [Loaders.css](https://connoratherton.com/loaders)
* [Slick Carousel](https://kenwheeler.github.io/slick)
* [Smooth Scroll](https://github.com/cferdinandi/smooth-scroll)
* [Sticky Kit](http://leafo.net/sticky-kit)
* [JVectorMap](http://jvectormap.com)
* [Font Awesome](https://fontawesome.com)
* [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release)
* [ControlLoRA](https://github.com/HighCWu/ControlLoRA)
* [IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1)
* [diffusers](https://github.com/huggingface/diffusers)
* [DeepL](https://www.deepl.com/translator)
* [svjack/Stable-Diffusion-Chinese-Extend](https://github.com/svjack/Stable-Diffusion-Chinese-Extend)
* [svjack/Stable-Diffusion-Pokemon](https://github.com/svjack/Stable-Diffusion-Pokemon)
* [svjack](https://huggingface.co/svjack)
-->
* [nlp-waseda/comet-atomic-ja](https://github.com/nlp-waseda/comet-atomic-ja)
* [ATOMIC paper](https://arxiv.org/pdf/1811.00146.pdf)
* [peft](https://github.com/huggingface/peft)
* [svjack](https://huggingface.co/svjack)
